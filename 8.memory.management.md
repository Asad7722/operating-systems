Memory Management
===

### Overview
- Background
- Swapping
- Contiguous Memory Allocation
- Paging
- Structure of the Page Table
- Segmentation
- Example: The Intel Pentium

### Objectives
- To provide a detailed description of various ways of organizing memory
hardware
- To discuss various memory-management techniques, including paging
and segmentation
- To provide a detailed description of the Intel Pentium, which supports both
pure segmentation and segmentation with paging

### Background
- Memory is central to the operation of a modern computer system
  -  Processes must be in main memory to be executed.
    - Processes share memory as well as CPU for good performance.
  -  Main memory and registers are only storage CPU can access directly
    - Register access in one CPU clock
    - Main memory can take many cycles, causing **stall**
  -  **Cache** sits between main memory and CPU registers
- Memory consists of a large array of words or bytes, each with its own
address
  -  A sequence of memory addresses without knowing what they are for or how
they are generated.
- Various ways to manage memory
  -  Primitive bare-machine approach
  -  Paging and segmentation.
  -  Protection of memory required to ensure correct operation

### Base and Limit Registers
- One possible implementation – each process has a separate space
- A pair of **base** and **limit registers** define the logical address space
- CPU must check every memory access generated in user mode to
be sure it is between base and limit for that user
- Base and limit registers are loaded by OS as privileged
instructions =>
  - User programs cannot change registers’ content

![title](http://www.cs.odu.edu/~cs471w/spring12/lectures/MainMemory_files/image002.jpg)

### Hardware Address Protection

![Hardware Address Protection](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_02_HardwareAddressProtection.jpg)

### Address Binding
- Program must be brought into memory and
placed within a process for it to be run.
- Input queue – collection of processes on the
disk that are waiting to be brought into
memory to run the program.
- User programs go through several steps
before being executed.
  -  Addresses in different ways during these steps:
    - Symbolic addresses in source program
    - Relocatable addresses in compilation
    - Absolute addresses in loading or linking
- Binding is a mapping from one address space
to another.

![Multistep Processing of a User Program ](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_03_MultistepProcessing.jpg)

*Multistep Processing of a User Program*

### Binding of Instructions and Data to Memory
- Address binding of instructions and data to memory addresses can be
done at three different stages
  -  **Compile time**: If memory location known a priori, **absolute code**
can be generated; must recompile code if starting location changes
(e.g., MS-DOS .COM format programs)
  -  **Load time**: Must generate **relocatable code** if memory location is
not known at compile time (IBM OS/360)
  -  **Execution time**: Binding delayed until run time if the process can be
moved during its execution from one memory segment to another.
Need hardware support for address maps (e.g., MMU)

### Dynamic Linking
- **Static linking** – System libraries are combined by the loader into the
executable image => Creates a big program
- **Dynamic linking** – Linking is postponed until execution time.
  -  A stub included in the image for each library-routine reference.
  -  Dynamic linking is particularly useful for libraries – shared libraries.
- Small piece of code, **stub**, used to locate the appropriate memoryresident
library routine.
  -  Stub replaces itself with the address of the routine and executes it
  -  Next time, the library routine will be in memory and exed directly
- Operating system checks if routine is in processes memory address
- If not in address space, add to address space
- System also known as **shared libraries**

### Logical vs. Physical Address Space
- Two addresses:
  -  **Logical address** – generated by the CPU; also referred to as
virtual address.
  -  **Physical address** – address seen by the memory unit.
- Logical and physical addresses are the same in compile-time and
load-time address-binding schemes.
- Logical and physical addresses differ in execution-time address-binding
scheme.
- **Memory-management unit** (**MMU**): Hardware device that is needed
to map virtual addresses to physical addresses.
  -  Simple MMU scheme using a relocation (base) register.

### Dynamic Relocation
- The value in **relocation
register** is added to every
address generated by a
user process at the time it
is sent to memory.
- The user program deals
with *logical* addresses; it
never sees the *real*
physical addresses.
- MMU maps the logical
address dynamically by
adding the value in the
relocation register; the
mapped address is sent to
memory.

![Dynamic Relocation](https://worldfullofquestions.files.wordpress.com/2014/07/memory-management-unitmmu.jpg)

### Dynamic Loading
- **Static loading**: Entire program and data are loaded at one time into
physical memory for the process to run => *Consumes more memory*
- **Dynamic loading**: Routine is not loaded until it is called
  -  Calling routine checks to see if the callee has been loaded
  -  Relocatable linking loader is used to load the desired routine.
- Better memory-space utilization
  -  Unused routine is never loaded
  -  All routines kept on disk in relocatable load format
  -  Useful when large amounts of code are needed to handle infrequently
occurring cases.
- No special support from the operating system is required
  -  Implemented through program design
  -  OS can help by providing libraries to implement dynamic loading

### Swapping
- A process can be swapped temporarily out of memory to a backing
store, and then brought back into memory for continued execution
  -  Useful in RR scheduling => An illusion of a big memory space
- **Roll out, roll in** – swapping variant used for priority-based
scheduling algorithms; lower-priority process is swapped out so
higher-priority process can be loaded and executed.
- **Backing store** – fast disk large enough to accommodate copies of
all memory images for all users; must provide direct access to
these memory images.
- Process must be completely idle for it to be swapped.
  -  Context-switch time can be fairly high.
  -  Total transfer time is directly proportional to the *amount* of memory
swapped.

### Schematic View of Swapping

![Schematic View of Swapping](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_05_ProcessSwapping.jpg)

### Context Switch Time including Swapping
- If next processes to be put on CPU is not in memory, need to
swap out a process and swap in target process
- Context switch time can then be very high
- 100MB process swapping to hard disk with transfer rate of
50MB/sec
  -  Swap out time of 2000 ms
  -  Plus swap in of same sized process
  -  Total context switch swapping component time of 4000ms
(4 seconds)
- Can reduce if reduce size of memory swapped – by knowing
how much memory really being used
  -  System calls to inform OS of memory use via
`request_memory()` and `release_memory()`
- **Other constraints**: Pending I/O – What if a process has a pending I/O?
  -  Data may be transferred to a wrong process that uses the same
memory space
  -  Two solutions
    - Don’t swap out such a process with pending I/Os
    - Or transfer I/O to kernel space, then to I/O device
– Known as **double buffering**, adds overhead
- Standard swapping not used in modern operating systems
  -  But modified version common
    - Swap only when free memory extremely low
    - OOM killer

### Swapping on Mobile Systems
- Not typically supported
  -  Flash memory based
    - Small amount of space
    - Limited number of write cycles
    - Poor throughput between flash memory and CPU on mobile
platform (eMMC provides better performance though)
- Instead use other methods to free memory if low
  -  iOS **asks** apps to voluntarily relinquish allocated memory
    - Read-only data thrown out and reloaded from flash if needed
    - Failure to free can result in termination
  -  Android terminates apps if low free memory, but first writes
  **application state** to flash for fast restart
  -  Both OSes support paging as discussed below

### Contiguous Allocation
- Main memory usually into two partitions:
  -  Resident operating system, usually held in **low memory** with
interrupt vector
  -  User processes then held in **high memory**
- In **contiguous memory allocation**, each process is contained in a
_single contiguous_ section of memory
- **Relocation registers** used to protect user processes from each
other, and from changing operating-system code and data
  -  **Base register** contains value of smallest physical address
  -  **Limit register** contains range of logical addresses – each
logical address must be less than the limit register
  -  MMU maps logical address *dynamically*
- **Multiple-partition allocation**
  -  Memory is partitioned. Each partition may contain exactly one process
  -  **Hole** – block of available memory; holes of various size are *scattered*
throughout memory
  -  When a process arrives, it is allocated memory from a hole large
enough to accommodate it
  -  Operating system maintains information about a) allocated partitions
b) free partitions (hole)

![title](http://www.massey.ac.nz/~mjjohnso/notes/59305/mod8d2.gif)

### Hardware Support for Relocation and Limit Registers

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_02_HardwareAddressProtection.jpg)
![title](http://www.cs.odu.edu/~cs471w/spring15/lectures/MainMemory_files/image002.jpg)
A pair of **base** and **limit** registers
define the address space

### Dynamic Storage-Allocation Problem

How to satisfy a request of size n from a list of free holes
- **First-fit**: Allocate the *first* hole that is big enough
- **Best-fit**: Allocate the *smallest* hole that is big enough; must search
entire list, unless ordered by size
  -  Produces the smallest leftover hole
- **Worst-fit**: Allocate the *largest* hole; must also search entire list
  -  Produces the largest leftover hole


*Simulation shows first-fit and best-fit are better than worst-fit
in terms of speed and storage utilization. Neither first-fit or
best-fit is clearly better than the other in turns of storage
utilization, but first-fit is faster.*

### Fragmentation
- **External Fragmentation** – total memory space exists to satisfy a
request, but it is not contiguous
- **Internal Fragmentation** – allocated memory may be slightly
larger than requested memory; this size difference is memory
internal to a partition, but not being used
- Reduce external fragmentation by **compaction**
  -  Shuffle memory contents to place all free memory together in
one large block
  -  Compaction is possible only if relocation is **dynamic**
(otherwise, you cannot move memory), and is done at
execution time

### Segmentation
- Memory-management scheme that supports user view of memory
- In the view of a programmer, a program is a collection of segments
  -  A segment is a logical unit such as:
main program
procedure
function
method
object
local variables, global variables
common block
stack
symbol table
arrays

![User’s view of a Program](http://i.imgur.com/CFZjdSb.png)

*User’s view of a Program*

### Logical View of Segmentation

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_09_Segmentation.jpg)

### Segmentation Architecture
- Logical address consists of a two tuple: ``<segment-number, offset>`
- **Segment table** – maps two-dimensional physical addresses; each
table entry has:
  -  **base** – contains the starting physical address where the
segments reside in memory
  -  **limit** – specifies the length of the segment
- **Segment-table base register** (**STBR**) points to the segment
tables location in memory
- **Segment-table length register** (**STLR**) indicates number of
segments used by a program;
 segment number `s` is legal if `s < STLR`
- Protection
  -  With each entry in segment table associate:
    - validation bit = 0 ⇒ illegal segment
    - read/write/execute privileges
- Segment-level: Protection bits associated with segments; code
sharing occurs at segment level (vs. page level in the paging
scheme)
- Since segments vary in length, memory allocation is a dynamic
storage-allocation problem
- A segmentation example is shown in the following diagram

### Segmentation Hardware

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_08_SegmentationHardware.jpg)

### Example of Segmentation

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_09_Segmentation.jpg)

### Paging Model of Logical and Physical Memory

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_11_PagingModel.jpg)

### Paging: Noncontiguous Allocation
- Divide physical memory into **fixed-sized** blocks called **frames**.
- Divide logical memory into blocks of same size called **pages**.
- Address generated by CPU is divided into two parts:
  -  **Page number** (**p**) – used as an index into a page table which
contains base address of each page in physical memory.
  -  **Page offset** (**d**) – combined with base address to define the physical memory address that is sent to the memory unit.

| page number  | page offset |
|---|---|
| p  | d  |
| m-n  | n  |

Size of logical space is 2^m
Size of page is 2^n

### Paging Hardware

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_10_PagingHardware.jpg)

### Paging Example

- Mapping the user’s view of
memory (i.e., logical
memory) into physical
memory
- A page size of 4 bytes
A physical memory of 32
bytes (equivalent to 8
frames).
Logical address 3 maps to
physical address 23.

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_12_PagingExample.jpg)

### Free Frames

Before allocation After allocation

OS keeps track of all free frames in a **Frame Table** – To run a program
of size n pages, need to find n free frames and load program.

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_13_FreeFrames.jpg)

### Fragmentation in Paging
- **No external fragmentation**: Every frame can essentially be used.
- Internal fragmentation: Last frame allocated may not be completely full.
A process would need n pages plus one byte requiring allocation of
n + 1 frames, resulting in an internal fragmentation of almost an entire
frame.
- Calculate the size of **internal fragmentation** for a process of
 72766 bytes and page size of 2048 bytes.
- Calculating internal fragmentation
  -  Page size = 2,048 bytes
  -  Process size = 72,766 bytes
  -  35 pages + 1,086 bytes
  -  Internal fragmentation of 2,048  -  1,086 = 962 bytes
  -  Worst case fragmentation = 1 frame – 1 byte
  -  On average fragmentation = 1 / 2 frame size
  -  So small frame sizes desirable? – Not exactly
    - Needs a big page table – each PT entry takes memory to track
    - Needs a big **Translation Lookaside Table** (**TLB**)
  -  Page sizes growing over time (memory is growing)
    - Solaris supports two page sizes – 8 KB and 4 MB
- Process view and physical memory now very different
  -  Process see a single contiguous space, while physical pages scattered
  -  By implementation process can only access its own memory

### Implementation of Page Table
- Page table is kept in main memory
  -  Most OSes allocate one page table for each process
  -  **Page-table base register** (**PTBR**) points to the page table
  -  **Page-table length register** (**PRLR**) indicates size of the page
table
- Two memory access problem
  -  In this scheme every data/instruction access requires two
memory accesses. One for the page table and one for the page
content (data/instruction).
  -  The two memory access problem can be solved by the use of a
special fast-lookup hardware cache called **associative memory**
or **translation look-aside buffers** (**TLBs**)
- Some TLBs store **address-space identifiers** (**ASIDs**) in each
TLB entry – uniquely identifies each process to provide address-space
protection for that process
  -  Otherwise need to flush at every context switch
  -  **TLB shootdown** – flush TLBs in multi-core processors
- TLBs typically small (64 to 1,024 entries)
- On a TLB miss, value is loaded into the TLB for faster access
next time
  -  Replacement policies must be considered
  -  Some entries can be **wired down** for permanent fast access

### Paging Hardware With TLB

![title](http://2.bp.blogspot.com/-E4L9abkiuJI/UN-zbQvGLEI/AAAAAAAAAbc/axtMcA2CKbw/s1600/CropperCapture%5B42%5D.Bmp)

### Effective Access Time
- Associative Lookup = ε time unit
  -  Can be < 10% of memory access time
- Hit ratio = α
  -  Hit ratio – percentage of times that a page number is found
in the associative registers; ratio related to number of
associative registers
- Consider α = 80%, ε = 20ns for TLB search, 100ns for memory
access
- **Effective Access Time** (**EAT**)
EAT = (100 + ε) α + (200 + ε)(1 – α)
- Consider α = 80%, ε = 20ns for TLB search, 100ns for memory
access
  -  EAT = 0.80 x 120 + 0.20 x 220 = 140ns
- Consider more realistic hit ratio  - > α = 99%, ε = 20ns for TLB
search, 100ns for memory access
  -  EAT = 0.99 x 120 + 0.01 x 220 = 121ns

### Memory Protection
- Page table entry contains bits for memory protection
- Memory protection implemented by associating protection bit
with each frame to indicate if read-only or read-write access is
allowed (at a finer granularity, compared to segmentation)
  -  Can also add more bits to indicate page execute-only, and
so on
- **Valid-invalid** bit attached to each entry in the page table:
  -  Valid indicates that the associated page is in the process
logical address space, and is thus a legal page
  -  Invalid indicates that the page is not in the process
logical address space
  -  Or use **page-table length register** (**PTLR**)
- Any violations result in a trap to the kernel

### Valid (v) or Invalid (i) Bit In A Page Table

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_15_ValidBits.jpg)

### Shared Pages
- Page table also enables **page sharing**
- **Shared code**
  -  One copy of read-only (**reentrant**) code shared among
processes (i.e., text editors, compilers, window systems)
  -  Similar to multiple threads sharing the same process space
  -  Also useful for inter-process communication if sharing of
read-write pages is allowed
- **Private code and data**
  -  Each process keeps a separate copy of the code and data
  -  The pages for the private code and data can appear
anywhere in the logical address space

### Shared Pages Example

![title](http://www.cs.odu.edu/~cs471w/spring12/lectures/MainMemory_files/image026.jpg)

### Structure of the Page Table
- Memory structures for paging can get huge using straight-forward
methods as logical address space grows
  -  Consider a 32-bit logical address space as on modern
computers
  -  Page size of 4 KB (2^12)
  -  Page table would have 1 million entries (2^32 / 2^12)
  -  If each entry is 4 bytes  - > 4 MB of physical address space /
memory for page table alone
    - That amount of memory used to cost a lot
    - Dont want to allocate that contiguously in main memory
  -  Process may not use the entire address space

### Structure of the Page Table
- Hierarchical Paging
- Hashed Page Tables
- Inverted Page Tables

### Hierarchical Page Tables
- Break up the logical address space into multiple page tables
- A simple technique is a two-level page table
- We then page the page table

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_17_TwoLevelPageTable.jpg)

### Two-Level Paging Example
- A logical address (on 32-bit machine with 1K page size) is divided into:
  -  a page number consisting of 22 bits
  -  a page offset consisting of 10 bits
- Since the page table is paged, the page number is further divided into:
  -  a 12-bit page number
  -  a 10-bit page offset
- Thus, a logical address is as follows:

|  page number ||  page offset |
| --- | --- | --- |
|  p1 | p2  | d  |
| 12  | 10  | 10  |

where p1 is an index into the outer page table, and p2 is the displacement
within the page of the inner page table

### Address-Translation Scheme

![title](http://i.imgur.com/pMdAhuH.png)

Known as **forward-mapped page table**

### 64-bit Logical Address Space
- Even two-level paging scheme not sufficient
- If page size is 4 KB (2^12)
  -  Then page table has 2^52 entries
  -  If two level scheme, inner page tables could be 2^10 4-byte entries
  -  Address would look like

|  outer page | inner page |  page offset |
| --- | --- | --- |
|  p1 | p2  | d  |
| 42  | 10  | 12  |

  -  Outer page table has 2^42 entries or 2^44 bytes
  -  One solution is to add a 2nd outer page table
  -  But in the following example the 2nd outer page table is still 234 bytes in size
    - And possibly 4 memory access to get to one physical memory location

### Three-level Paging Scheme

![title](http://i.imgur.com/eAVHaSB.png)

### Hashed Page Tables
- Common in address spaces > 32 bits
- The virtual page number is hashed into a page table
  -  This page table contains a chain of elements hashing to the same
location
- Each element contains (1) the virtual page number (2) the value of the
mapped page frame (3) a pointer to the next element
- Virtual page numbers are compared in this chain searching for a
match
  -  If a match is found, the corresponding physical frame is extracted
- Variation for 64-bit addresses is **clustered page tables**
  -  Similar to hashed but each entry refers to several pages (such as
16) rather than 1
  -  Especially useful for **sparse** address spaces (where memory
references are non-contiguous and scattered)

### Hashed Page Table

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_19_HashedPageTable.jpg)

### Inverted Page Table
- Rather than each process having a page table and keeping track of all
possible logical pages, track all physical pages => **physical memory
space is small relative to logical memory space**
- One entry for each real page of memory
- Entry consists of the virtual address of the page stored in that real
memory location, with information about the process that owns that page
- **Decreases memory** needed to store each page table, but **increases
time** needed to search the table when a page reference occurs (because
CPU uses logical address)
  -  Use hash table to limit the search to one — or at most a few — page-table
entries
  -  TLB can accelerate access
- But how to implement shared memory?
  -  Only allow one mapping of a virtual address to the shared physical
address

### Inverted Page Table Architecture

![title](http://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter8/8_20_InvertedPageTable.jpg)
